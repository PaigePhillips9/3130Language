{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Scraper - Using Tweepy via Twitter API Dev\n",
    "### Scott Ackerl\n",
    "There are limitations in using Tweepy for scraping tweets. The standard API only allows you to retrieve tweets up to 7 days ago and is limited to scraping 18,000 tweets per a 15 minute window. However, it is possible to increase this limit as shown here. Also, using Tweepy you’re only able to return up to 3,200 of a user’s most recent tweets. Using Tweepy is great for someone who is trying to make use of Twitter’s other functionality, making complex queries, or wants the most extensive information provided for each tweet.\n",
    "\n",
    "Need ones with lots of re-tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credientials\n",
    "consumer_key = \"HWnp2NqeRQExY2ZTxFixOv4mE\"\n",
    "consumer_secret = \"ODRPESnZEpOm9CCw4sefdD88JxZurkRbhFq6NoEUjSzDegiLdp\"\n",
    "access_token = \"1250094860507516929-7pSEuy0MNMzIrkpTTkEoYTbTG7nEnf\"\n",
    "access_token_secret = \"jT2HzB0pUhbH0dlJac11ualeUYcpY7LEWwrN91IRfRJ5Z\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query by Text Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of tweets\n",
    "tweets = []\n",
    "\n",
    "def text_query_to_csv(text_query,count):\n",
    "    tweets = []\n",
    "    try:\n",
    "    # Pulling individual tweets from query\n",
    "        for tweet in api.search(q=text_query, count=count):\n",
    "\n",
    "          # Adding to list that contains all tweets\n",
    "          tweets.append((tweet.created_at,tweet.id,tweet.text))\n",
    "\n",
    "          # Creation of dataframe from tweets list\n",
    "          tweetsdf = pd.DataFrame(tweets,columns=['Datetime', 'Tweet Id', 'Text'])\n",
    "\n",
    "          # Converting dataframe to CSV\n",
    "          tweetsdf.to_csv('{}-tweets.csv'.format(text_query)) \n",
    "\n",
    "    except BaseException as e:\n",
    "        print('failed on_status,',str(e))\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input search query to scrape tweets and name csv file\n",
    "# Max recent tweets pulls x amount of most recent tweets from that user\n",
    "text_query = 'Trump'\n",
    "count = 300\n",
    "\n",
    "# Calling function to query X amount of relevant tweets and create a CSV file\n",
    "text_query_to_csv(text_query, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
